{
 "metadata": {
  "name": "",
  "signature": "sha256:d51406375ff2052b95bf28584522db8060a299a275536629ac5d3cc82a4037a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Relating Age to Name\n",
      "\n",
      "This notebook is inspired by [Nate Silver's](https://twitter.com/FiveThirtyEight) recent article on [How to Tell Someone's Age When All you Know is Her Name](http://fivethirtyeight.com/features/how-to-tell-someones-age-when-all-you-know-is-her-name/). It allows one to (almost) replicate the analysis done in the article, and provides more extensive features. I have done similar work using R, and you can find it [here](https://github.com/ramnathv/agebyname)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data\n",
      "\n",
      "We will uses four primary datasets.\n",
      "\n",
      "1. [Babynames](http://www.ssa.gov/oact/babynames/names.zip)\n",
      "2. [Babynames by State](http://www.ssa.gov/oact/babynames/state/namesbystate.zip)\n",
      "3. [Cohort Life Tables](http://www.ssa.gov/oact/NOTES/as120/LifeTables_Tbl_7.html)\n",
      "4. [Census Live Births Data](http://www.census.gov/statab/hist/02HS0013.xls)\n",
      "\n",
      "We will download each of these datasets and process them to get them analysis ready."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import re\n",
      "import urllib\n",
      "from zipfile import ZipFile\n",
      "from path import path\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy.interpolate import interp1d\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from ggplot import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/ramnathv/anaconda/lib/python2.7/site-packages/pytz/__init__.py:29: UserWarning: Module argparse was already imported from /Users/ramnathv/anaconda/lib/python2.7/argparse.pyc, but /Users/ramnathv/anaconda/lib/python2.7/site-packages is being added to sys.path\n",
        "  from pkg_resources import resource_stream\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Baby Names\n",
      "\n",
      "The first dataset we will be downloading is the [bnames](http://www.ssa.gov/oact/babynames/names.zip) dataset provided by SSA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urllib.urlretrieve(\"http://www.ssa.gov/oact/babynames/names.zip\", \"names.zip\")\n",
      "zf = ZipFile(\"names.zip\")\n",
      "def read_names(f):\n",
      "  data = pd.read_csv(zf.open(f), header = None, names = ['name', 'sex', 'n'])\n",
      "  data['year'] = int(re.findall(r'\\d+', f)[0])\n",
      "  return data\n",
      "  \n",
      "bnames = pd.concat([read_names(f) for f in zf.namelist() if f.endswith('.txt')])\n",
      "bnames.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>sex</th>\n",
        "      <th>n</th>\n",
        "      <th>year</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      Mary</td>\n",
        "      <td> F</td>\n",
        "      <td> 9217</td>\n",
        "      <td> 1884</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>      Anna</td>\n",
        "      <td> F</td>\n",
        "      <td> 3860</td>\n",
        "      <td> 1884</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      Emma</td>\n",
        "      <td> F</td>\n",
        "      <td> 2587</td>\n",
        "      <td> 1884</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Elizabeth</td>\n",
        "      <td> F</td>\n",
        "      <td> 2549</td>\n",
        "      <td> 1884</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>    Minnie</td>\n",
        "      <td> F</td>\n",
        "      <td> 2243</td>\n",
        "      <td> 1884</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "        name sex     n  year\n",
        "0       Mary   F  9217  1884\n",
        "1       Anna   F  3860  1884\n",
        "2       Emma   F  2587  1884\n",
        "3  Elizabeth   F  2549  1884\n",
        "4     Minnie   F  2243  1884\n",
        "\n",
        "[5 rows x 4 columns]"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Baby Names by State\n",
      "\n",
      "The second dataset we will be downloading is the [bnames_by_state](http://www.ssa.gov/oact/babynames/namesbystate.zip) dataset, also provided by SSA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urllib.urlretrieve(\"http://www.ssa.gov/oact/babynames/state/namesbystate.zip\", \"namesbystate.zip\")\n",
      "zf = ZipFile(\"namesbystate.zip\")\n",
      "def read_names2(f):\n",
      "  return pd.read_csv(zf.open(f), header = None, names = ['state', 'sex', 'year', 'name', 'n'])\n",
      "  \n",
      "bnames_by_state = pd.concat([read_names2(f) for f in zf.namelist() if f.endswith('.TXT')])\n",
      "bnames_by_state.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Cohort Life Tables\n",
      "\n",
      "The next dataset is actuarial [cohort life tables](http://www.ssa.gov/oact/NOTES/as120/LifeTables_Tbl_7.html) provided by SSA. I was unable to figure out how to scrape this data using `BeautifulSoup`. So I used the R package `XML` to scrape these lifetables and saved it to [lifetables.csv](lifetables.csv). If you are interested in the R code, you can find it [here](https://github.com/ramnathv/agebyname/blob/master/rawdata/lifetables.R)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lifetables = pd.read_csv('lifetables.csv')\n",
      "lifetables.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can read the documentation for the lifetables to understand the various parameters. The key column of interest to us is `lx`, which provides the number of people born in the year `year` who live upto the age `x`. Since we are in the year 2014, we are only interested in a subset of the data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lifetables_2014 = lifetables[lifetables['year'] + lifetables['x'] == 2014]\n",
      "lifetables_2014.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The cohort life tables are provided only for every decade. Since we need the data by year, we will use spline interpolation to fill out the gaps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process(d, kind = 'slinear'):\n",
      "  f = interp1d(d.year, d.lx, kind)\n",
      "  year = np.arange(1900, 2011)\n",
      "  lx = f(year)\n",
      "  return pd.DataFrame({\"year\": year, \"lx\": lx, \"sex\": d.sex.iloc[1]})\n",
      "lifetable_2014 = lifetables_2014.\\\n",
      "  groupby('sex', as_index = False).\\\n",
      "  apply(process)\n",
      "lifetable_2014.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Census Live Births Data\n",
      "\n",
      "Finally, we need [live births data](http://www.census.gov/statab/hist/02HS0013.xls) from the census to extrapolate the birth data to account for the correct that not all births were recorded by SSA till around 1930, since it wasn't mandatory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urllib.urlretrieve(\"http://www.census.gov/statab/hist/02HS0013.xls\", \"02HS0013.xls\")\n",
      "dat = pd.read_excel('02HS0013.xls', sheetname = 'HS-13', skiprows = range(14))\n",
      "tot_births = dat.ix[9:101,:2].reset_index(drop = True)\n",
      "tot_births.columns = ['year', 'births']\n",
      "tot_births = tot_births.convert_objects(convert_numeric = True)\n",
      "tot_births.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now merge this data with the `bnames` aggregated by `year` to compute a set of correction factors, which will be used to scale the number of births. I have taken a very naive approach to do this, and there might be better ways to accomplish the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cor_factors = bnames.\\\n",
      "  groupby('year', as_index = False).\\\n",
      "  sum().\\\n",
      "  merge(tot_births)\n",
      "cor_factors['cor'] = cor_factors['births']*1000/cor_factors['n']\n",
      "cor_factors = cor_factors[['year', 'cor']]\n",
      "cor_factors.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We expand the correction factors data for the years 2002 to 2014 using the correction factor for the year 2001."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cor_new = pd.DataFrame({\n",
      "  'year': range(2002, 2014),\n",
      "  'cor': cor_factors.cor.iloc[-1]\n",
      "})\n",
      "cor_factors = pd.concat([cor_factors, cor_new])[['year', 'cor']]\n",
      "cor_factors.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Analysis\n",
      "\n",
      "Now that we have all the required data, we need a few helper functions to help us with our analysis. The first function we will write is `get_data`, which takes `name`, `sex` and `state` and returns a data frame with the distribution of number of births and number of people alive by year."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(name, sex, state = None):\n",
      "  if state is None:\n",
      "    dat = bnames\n",
      "  else:\n",
      "    dat = bnames_by_state[(bnames_by_state[\"state\"] == state)]\n",
      "  data = dat[(dat['name'] == name) & (dat['sex'] == sex)].\\\n",
      "    merge(cor_factors).\\\n",
      "    merge(lifetable_2014)\n",
      "  data['n_cor'] = data['n']*data['cor']\n",
      "  data['n_alive'] = data['lx']/(10**5)*data['n_cor']\n",
      "  return data\n",
      "get_data('Violet', 'F').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our next helper function is `plot_name` which accepts the same arguments as `get_data`, but returns a plot of the distribution of number of births and number alive by year."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_name(name, sex, state = None):\n",
      "  data = get_data(name, sex, state)\n",
      "  return ggplot(data, aes('year', 'n_cor')) +\\\n",
      "    geom_line() +\\\n",
      "    geom_area(aes(ymin = 0, ymax = 'n_alive'), alpha = 0.5)\n",
      "plot_name(\"Joseph\", \"F\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_name(\"Violet\", \"F\", \"MA\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Estimate Age\n",
      "\n",
      "We will now write a function that will help us figure out the probability that a person with a certain name is alive, as well as the quantiles of their age distribution. Since we are dealing with weighted data, I will use some code copied from the [wquantiles](https://github.com/nudomarinero/wquantiles/) module. The `quantile` function accepts a data array and a weights array to return a specific quantile"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from the module wquantiles https://github.com/nudomarinero/wquantiles/blob/master/weighted.py\n",
      "import numpy as np\n",
      "def quantile_1D(data, weights, quantile):\n",
      "    \"\"\"\n",
      "    Compute the weighted quantile of a 1D numpy array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    data : ndarray\n",
      "        Input array (one dimension).\n",
      "    weights : ndarray\n",
      "        Array with the weights of the same size of `data`.\n",
      "    quantile : float\n",
      "        Quantile to compute. It must have a value between 0 and 1.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    quantile_1D : float\n",
      "        The output value.\n",
      "    \"\"\"\n",
      "    # Check the data\n",
      "    if not isinstance(data, np.matrix) :\n",
      "        data = np.asarray(data)\n",
      "    if not isinstance(weights, np.matrix) :\n",
      "        weights = np.asarray(weights)\n",
      "    nd = data.ndim\n",
      "    if nd != 1:\n",
      "        raise TypeError(\"data must be a one dimensional array\")\n",
      "    ndw = weights.ndim\n",
      "    if ndw != 1:\n",
      "        raise TypeError(\"weights must be a one dimensional array\")\n",
      "    if data.shape != weights.shape:\n",
      "        raise TypeError(\"the length of data and weights must be the same\")\n",
      "    if ((quantile > 1.) or (quantile < 0.)):\n",
      "        raise ValueError(\"quantile must have a value between 0. and 1.\")\n",
      "    # Sort the data\n",
      "    ind_sorted = np.argsort(data)\n",
      "    sorted_data = data[ind_sorted]\n",
      "    sorted_weights = weights[ind_sorted]\n",
      "    # Compute the auxiliary arrays\n",
      "    Sn = np.cumsum(sorted_weights)\n",
      "    # TODO: Check that the weights do not sum zero\n",
      "    Pn = (Sn-0.5*sorted_weights)/np.sum(sorted_weights)\n",
      "    # Get the value of the weighted median\n",
      "    return np.interp(quantile, Pn, sorted_data)\n",
      "\n",
      "\n",
      "def quantile(data, weights, quantile):\n",
      "    \"\"\"\n",
      "    Weighted quantile of an array with respect to the last axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    data : ndarray\n",
      "        Input array.\n",
      "    weights : ndarray\n",
      "        Array with the weights. It must have the same size of the last \n",
      "        axis of `data`.\n",
      "    quantile : float\n",
      "        Quantile to compute. It must have a value between 0 and 1.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    quantile : float\n",
      "        The output value.\n",
      "    \"\"\"\n",
      "    # TODO: Allow to specify the axis\n",
      "    nd = data.ndim\n",
      "    if nd == 0:\n",
      "        TypeError(\"data must have at least one dimension\")\n",
      "    elif nd == 1:\n",
      "        return quantile_1D(data, weights, quantile)\n",
      "    elif nd > 1:\n",
      "        n = data.shape\n",
      "        imr = data.reshape((np.prod(n[:-1]), n[-1]))\n",
      "        result = np.apply_along_axis(quantile_1D, -1, imr, weights, quantile)\n",
      "        return result.reshape(n[:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will use the `quantile` function to write an `estimate_age` function that will return the living probabilities and quantiles for a given `name`, `sex` and `state`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def estimate_age(name, sex, state = None):\n",
      "  data = get_data(name, sex, state)\n",
      "  qs = [1, 0.75, 0.5, 0.25, 0]\n",
      "  quantiles = [2014 - int(quantile(data.year, data.n_alive, q)) for q in qs]\n",
      "  result = dict(zip(['q0', 'q25', 'q50', 'q75', 'q100'], quantiles))\n",
      "  result['p_alive'] = round(data.n_alive.sum()/data.n_cor.sum()*100, 2)\n",
      "  result['sex'] = sex\n",
      "  result['name'] = name\n",
      "  return pd.Series(result)\n",
      "  \n",
      "estimate_age('Gertrude', 'F')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimate_age('Ava', 'F')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use the `estimate_age` function to compute the quantiles for the most common names and replicate the plots in the Nate Silver article."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "top_100_names = bnames.\\\n",
      "  groupby(['name', 'sex'], as_index = False).\\\n",
      "  sum().\\\n",
      "  sort('n', ascending = False)\n",
      "top_25_females = top_100_names[(top_100_names[\"sex\"] == \"F\")]\n",
      "estimates = pd.concat([estimate_age(name, 'F') for name in top_25_females[\"name\"].iloc[:25].tolist()], axis = 1)\n",
      "estimates.T.sort('q50').reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can go a step beyond the article and also use the `state` parameter to get more specific quantiles, if we know the place of birth of a person.\n",
      "\n",
      "The final step for me is to convert all of this into an interactive webapp. I have done it with R using the [shiny](http://rstudio.com/shiny) package. I am still getting the hang of web frameworks in python, so it will be a while before I get to doing this."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}